{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import label_map_util\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import six\n",
    "from playsound import playsound\n",
    "import collections\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = os.path.join(\"inference_graph/labelmap.pbtxt\")\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Načtení modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "configs = config_util.get_configs_from_pipeline_file(\n",
    "    \"inference_graph/pipeline.config\")\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(\n",
    "    model_config=model_config, is_training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Načtení natrénovanách hodnot do modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f49bc44d410>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join('inference_graph/checkpoint/', 'ckpt-0')\n",
    "             ).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
    "\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predikce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_metadata(image_path, cnt, dataset_id=1):\n",
    "    image_metadata = {}\n",
    "    image_np = cv2.imread(image_path)\n",
    "    height, width, _ = image_np.shape\n",
    "    image_metadata['id'] = cnt\n",
    "    image_metadata['dataset_id'] = dataset_id\n",
    "    image_metadata['path'] = image_path\n",
    "    image_metadata['height'], image_metadata['width'] = height, width\n",
    "    image_metadata['file_name'] = os.path.basename(image_path)\n",
    "    return image_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_elephants(image_path):\n",
    "    image_np = cv2.imread(image_path)\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    min_score_thresh = 0.40\n",
    "\n",
    "    box_to_display_str_map = collections.defaultdict(list)\n",
    "    box_to_color_map = collections.defaultdict(str)\n",
    "\n",
    "    number_of_items = 0\n",
    "\n",
    "    for i in range(detections['detection_boxes'][0].numpy().shape[0]):\n",
    "\n",
    "        if detections['detection_scores'][0].numpy() is None or detections['detection_scores'][0].numpy()[i] > min_score_thresh:\n",
    "\n",
    "            box = tuple(detections['detection_boxes'][0].numpy()[i].tolist())\n",
    "\n",
    "            display_str = ''\n",
    "\n",
    "            if (detections['detection_classes'][0].numpy() + label_id_offset).astype(int)[i] in six.viewkeys(category_index):\n",
    "                class_name = category_index[(detections['detection_classes'][0].numpy() + label_id_offset).astype(int)[i]]['name']\n",
    "                display_str = str(class_name)\n",
    "                display_str = '{}: {}%'.format(display_str, round(\n",
    "                    100*detections['detection_scores'][0].numpy()[i]))\n",
    "\n",
    "                box_to_display_str_map[box].append(display_str)\n",
    "\n",
    "                box_to_color_map[box] = \"Red\"\n",
    "\n",
    "                if \"Elephant\" in box_to_display_str_map[box][0]:\n",
    "                    number_of_items += 1\n",
    "    im_width, im_height = image_np.shape[1::-1]\n",
    "\n",
    "    for box, color in box_to_color_map.items():\n",
    "        ymin, xmin, ymax, xmax = box\n",
    "\n",
    "        ymin = ymin * im_height\n",
    "        xmin = xmin * im_width\n",
    "        ymax = ymax * im_height\n",
    "        xmax = xmax * im_width\n",
    "\n",
    "        x = xmin\n",
    "        y = ymin\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "\n",
    "        box_color = (0, 0, 0)\n",
    "\n",
    "        if color == \"Red\":\n",
    "            box_color = (0, 0, 255)\n",
    "\n",
    "        cv2.rectangle(image_np_with_detections, (int(x), int(y)),\n",
    "                        (int(x) + int(w), int(y) + int(h)), box_color, 4)\n",
    "        cv2.putText(image_np_with_detections, 'Elephant', (int(x), int(\n",
    "            y)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "    return image_np_with_detections, number_of_items, detections\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_metadata = []\n",
    "tf_detections = []\n",
    "\n",
    "directory = '../SLONI_label'\n",
    "for i, filename in enumerate(tqdm.tqdm(os.listdir(directory))):\n",
    "    image_path = os.path.join(directory, filename)\n",
    "    with tf.device('/GPU:0'):\n",
    "        image, count, detections = predict_elephants(image_path)\n",
    "    \n",
    "    tf_detections.append(detections)\n",
    "    metadata = get_image_metadata(image_path, i+1)\n",
    "    images_metadata.append(metadata)\n",
    "    # images.append(image)\n",
    "    # counts.append(count)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assuming `tf_detections` is a list where each item contains the TensorFlow detection results for an image\n",
    "# and `images_metadata` is a list of dictionaries with metadata for each image processed\n",
    "\n",
    "coco_output = {\n",
    "    \"images\": [],\n",
    "    \"categories\": [\n",
    "        {\"id\": 1, \"name\": \"Elephant\", \"supercategory\": \"\", \"color\": \"#3ab7dd\", \"metadata\": {}, \"keypoint_colors\": []}\n",
    "    ],\n",
    "    \"annotations\": []\n",
    "}\n",
    "annotation_id = 1\n",
    "def convert_to_coco(tf_detections, images_metadata):\n",
    "    global annotation_id \n",
    "    for image_metadata, detection in zip(images_metadata, tf_detections):\n",
    "        # Add image info\n",
    "        coco_output[\"images\"].append({\n",
    "            \"id\": image_metadata[\"id\"],\n",
    "            \"dataset_id\": image_metadata[\"dataset_id\"],\n",
    "            \"category_ids\": [],\n",
    "            \"path\": os.path.join('datasets', image_metadata[\"path\"]),\n",
    "            \"width\": image_metadata[\"width\"],\n",
    "            \"height\": image_metadata[\"height\"],\n",
    "            \"file_name\": image_metadata[\"file_name\"],\n",
    "            \"annotated\": False,\n",
    "            \"annotating\": [],\n",
    "            \"num_annotations\": 0,\n",
    "            \"metadata\": {},\n",
    "            \"deleted\": False,\n",
    "            \"milliseconds\": 0,\n",
    "            \"events\": [],\n",
    "            \"regenerate_thumbnail\": False\n",
    "        })\n",
    "\n",
    "        # Process each detection\n",
    "        for box, score, class_id in zip(detection['detection_boxes'][0], detection['detection_scores'][0], detection['detection_classes'][0]):\n",
    "            if score < 0.4:  # Assuming a threshold of 0.5 for this example\n",
    "                continue\n",
    "\n",
    "            # Convert TensorFlow box format to COCO format\n",
    "            ymin, xmin, ymax, xmax = box.numpy()\n",
    "            xmin = xmin * image_metadata[\"width\"]\n",
    "            ymin = ymin * image_metadata[\"height\"]\n",
    "            xmax = xmax * image_metadata[\"width\"]\n",
    "            ymax = ymax * image_metadata[\"height\"]\n",
    "            ymin, xmin, ymax, xmax = round(ymin, 1), round(xmin, 1), round(ymax, 1), round(xmax, 1)\n",
    "            x, y, w, h = xmin, ymin, (xmax - xmin), (ymax - ymin)\n",
    "            x, y, w, h = round(x, 1), round(y, 1), round(w, 1), round(h, 1)\n",
    "            segmentation_points = [xmin, ymin, xmax, ymin, xmax, ymax, xmin, ymax]\n",
    "\n",
    "            coco_output[\"annotations\"].append({\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": image_metadata[\"id\"],\n",
    "                \"category_id\": 1,\n",
    "                \"segmentation\": [segmentation_points],  # Add segmentation data here if available\n",
    "                \"area\": round(w * h, 0),\n",
    "                \"bbox\": [x, y, w, h],\n",
    "                \"iscrowd\": False,\n",
    "                \"isbbox\": True,\n",
    "                \"color\": \"#8eb517\", \n",
    "                \"metadata\": {}\n",
    "            })\n",
    "            annotation_id += 1\n",
    "\n",
    "    return coco_output\n",
    "\n",
    "# usage\n",
    "coco_dataset = convert_to_coco(tf_detections, images_metadata)\n",
    "with open('annotations.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(coco_dataset, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4671 [00:00<?, ?it/s]2024-02-08 23:02:28.929703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8600\n",
      "100%|██████████| 4671/4671 [16:30<00:00,  4.72it/s]   \n"
     ]
    }
   ],
   "source": [
    "# images_metadata = []\n",
    "# tf_detections = []\n",
    "\n",
    "# directory = '../SLONI_label'\n",
    "# for i, filename in enumerate(tqdm.tqdm(os.listdir(directory))):\n",
    "#     image_path = os.path.join(directory, filename)\n",
    "#     with tf.device('/GPU:0'):\n",
    "#         image, count, detections = predict_elephants(image_path)\n",
    "    \n",
    "#     tf_detections.append(detections)\n",
    "#     metadata = get_image_metadata(image_path, i+1)\n",
    "#     images_metadata.append(metadata)\n",
    "\n",
    "#     if i == len(os.listdir(directory))//2:\n",
    "#         coco_output = convert_to_coco(tf_detections, images_metadata)\n",
    "#         assert len(tf_detections) == len(images_metadata)\n",
    "#         tf_detections.clear()\n",
    "#         images_metadata.clear()\n",
    "\n",
    "# coco_dataset = convert_to_coco(tf_detections, images_metadata) \n",
    "# with open('annotations.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(coco_dataset, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
